runtime {
  required_version = "0.0.1"
}


variable "model_max_tokens" {
  type = "number"
  description = "Maximum number of tokens for model responses"
  default = 1000
}

variable "signature" {
  description = "Signature to use for messages"
  type        = string
  default     = "From Variable"
}

variable "model_provider" {
  type = "string"
  description = "Model provider to use (e.g. ollama, openai)"
  default = "openai"
}

variable "model_name" {
  type = "string"
  description = "Model name to use (e.g. gpt-4, gpt-3.5-turbo)"
  default = "gpt-4"
}

variable "debug_mode" {
  type = "bool"
  description = "Enable debug logging"
  default = false
}

variable "allowed_models" {
  type = "list"
  description = "List of allowed model names"
  default = ["gpt-4", "gpt-3.5-turbo"]
}

variable "model_settings" {
  type = "map"
  description = "Additional model settings"
  default = {
    context_window = 4096
    top_p = 0.9
  }
}

model "llama2_instance" {
  provider = var.model_provider
  name     = var.model_name
  settings {
    temperature = var.model_temperature
    max_tokens  = var.model_max_tokens
  }
}

plugin "local" "echo" {
  source = "./local_plugins/echo"
  variables = {
    "signature" = var.signature
  }
}

plugin "local" "code_editor" {
  source = "./local_plugins/code_editor"
  variables = {}
}

plugin "remote" "echo" {
  source = "onwardplatforms/echo"
  version = "0.0.1"
  variables = {}
}

agent "local" {
  name           = "test-agent-local-${model.llama2_instance.name}"
  description    = "A helpful coding assistant"
  system_prompt  = <<-EOT
    You are a helpful coding assistant. Follow this workflow when handling tasks:

    1. UNDERSTAND:
       - Carefully read and understand the user's request
       - Identify the type of change needed (e.g., HCL block, code lines, etc.)
       - Read plugin instructions to find the right tool for the job

    2. PLAN:
       - Choose ONE appropriate function based on file type and change needed
       - Explain which function you'll use and why
       - List all required parameters for the chosen function

    3. EXECUTE:
       - Use the chosen function with ALL required parameters
       - If a function call fails, understand why before trying a different approach
       - Provide clear explanations of what you're doing

    4. VERIFY:
       - Check that changes meet the requirements
       - Verify there are no unintended side effects
       - Suggest testing steps if needed

    Important Notes:
    - Plugin instructions provide specific guidance for different file types
    - Each plugin defines the correct functions for different operations
    - Never try multiple functions randomly - understand and use the right one
    - Always provide all required parameters for functions

    Remember: Accuracy and proper tool usage are more important than speed.
    EOT
  model          = model.llama2_instance
  plugins        = [plugin.local.echo, plugin.local.code_editor]
}

agent "remote" {
  name           = "test-agent"
  description    = "A test agent using Ollama provider"
  system_prompt  = "Always say Jeff"
  model          = model.llama2_instance
  plugins        = [plugin.remote.echo]
}
