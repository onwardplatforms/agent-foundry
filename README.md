# Agent Foundry

A tool for creating and managing AI agents. Agent Foundry provides a simple CLI for creating, managing, and interacting with AI agents.

## Features

- ğŸ”„ Real-time streaming responses
- ğŸ¯ Simple configuration-based agent creation
- ğŸ› ï¸ Multiple LLM provider support (OpenAI, Ollama)
- ğŸ“ Customizable system prompts
- ğŸ”Œ Per-agent environment configuration

## Installation

```bash
# Clone the repository
git clone https://github.com/yourusername/agent-foundry.git
cd agent-foundry

# Create and activate a virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install in editable mode
pip install -e .
```

## Configuration

You can configure environment variables at two levels:

1. Project-wide: Create a `.env` file in your project root
2. Per-agent: Create a `.env` file in `.agents/<agent_id>/.env`

Example `.env` files:

```bash
# Project-wide .env
OPENAI_API_KEY=your_api_key_here
OPENAI_MODEL=gpt-4  # Optional, defaults to gpt-3.5-turbo

# Ollama Settings
OLLAMA_HOST=http://localhost:11434  # Optional
OLLAMA_MODEL=llama2  # Optional
```

```bash
# Per-agent .env (.agents/my-agent/.env)
OPENAI_MODEL=gpt-4  # Override model just for this agent
```

## Usage

### Creating an Agent

Create a new agent with an optional name, provider, and system prompt:

```bash
# Create with OpenAI (default)
foundry create my-agent --provider openai --model gpt-4

# Create with Ollama
foundry create llama-agent --provider ollama --model llama2

# Create with custom system prompt
foundry create my-agent --system-prompt "You are a helpful coding assistant."

# Create with debug mode
foundry create my-agent --debug
```

### Running an Agent

Start an interactive chat session with an agent:

```bash
# Basic run
foundry run my-agent

# Run with debug mode
foundry run my-agent --debug
```

The agent will respond in real-time with streaming output.

### Listing Agents

List all available agents:

```bash
# Basic list
foundry list

# Detailed list with configurations
foundry list --verbose
```

### Deleting an Agent

Delete an agent:

```bash
# With confirmation prompt
foundry delete my-agent

# Force delete without confirmation
foundry delete my-agent --force
```

## Project Structure

```
agent-foundry/
â”œâ”€â”€ agent_foundry/          # Main package
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ agent.py           # Agent implementation
â”‚   â”œâ”€â”€ provider_impl.py   # Provider implementations
â”‚   â”œâ”€â”€ providers.py       # Provider definitions
â”‚   â”œâ”€â”€ env.py            # Environment handling
â”‚   â”œâ”€â”€ cli/              # CLI implementation
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ commands.py
â”‚   â””â”€â”€ constants.py       # Shared constants
â”œâ”€â”€ tests/                 # Test suite (83% coverage)
â”œâ”€â”€ .env                   # Global environment variables
â””â”€â”€ .agents/              # Agent storage directory
    â””â”€â”€ my-agent/         # Individual agent directory
        â”œâ”€â”€ config.json   # Agent configuration
        â””â”€â”€ .env          # Agent-specific environment
```

## Agent Configuration

Each agent is defined by a `config.json` file with the following structure:

```json
{
  "id": "my-agent",
  "system_prompt": "You are a helpful AI assistant.",
  "provider": {
    "name": "openai",
    "model": "gpt-4",
    "settings": {
      "temperature": 0.7,
      "top_p": 0.95,
      "max_tokens": 1000
    }
  }
}
```

### Provider Settings

#### OpenAI
```json
{
  "provider": {
    "name": "openai",
    "model": "gpt-4",  // Optional, falls back to OPENAI_MODEL or gpt-3.5-turbo
    "settings": {
      "temperature": 0.7,    // Optional, default: 0.7
      "top_p": 0.95,        // Optional, default: 0.95
      "max_tokens": 1000    // Optional, default: 1000
    }
  }
}
```

#### Ollama
```json
{
  "provider": {
    "name": "ollama",
    "model": "llama2",  // Optional, falls back to OLLAMA_MODEL or llama2
    "settings": {
      "temperature": 0.7,      // Optional, default: 0.7
      "base_url": "http://localhost:11434",  // Optional
      "context_window": 4096   // Optional, default: 4096
    }
  }
}
```

### Environment Variables

Settings precedence order (highest to lowest):
1. System environment variables
2. Agent-specific `.env` file (if exists)
3. Project-wide `.env` file
4. Default values

## Development

```bash
# Install development dependencies
pip install -e ".[dev]"

# Run tests
make test

# Run linting and type checking
make lint

# Run all checks
make all
```

## Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## License

This project is licensed under the MIT License - see the LICENSE file for details.

## Project Status

âœ… Core agent functionality
âœ… OpenAI provider implementation
âœ… Ollama provider implementation
âœ… Real-time streaming responses
âœ… Command-line interface
âœ… Per-agent environment variables
âœ… Test suite (83% coverage)
â³ Documentation site
â³ CI/CD pipeline

## Future Plans

- [ ] Add more provider implementations (Anthropic, etc.)
- [ ] Add conversation history persistence
- [ ] Add plugin system for custom capabilities
- [ ] Improve test coverage to 90%+
- [ ] Add comprehensive documentation site
